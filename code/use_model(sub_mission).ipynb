{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f00668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class CsvImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, img_root, transform=None, label_map=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.img_root = Path(img_root)\n",
    "        self.transform = transform if transform else transforms.Compose([\n",
    "            transforms.Resize((512,512)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "        ])\n",
    "        self.label_col = \"diagnosis_1\"\n",
    "        self.label2idx = {\"Benign\":0, \"Malignant\":1, \"Indeterminate\":1} if label_map is None else label_map\n",
    "\n",
    "\n",
    "        self.df['img_path'] = self.df['isic_id'].apply(self._find_file)\n",
    "\n",
    "    def _find_file(self, name):\n",
    "        for ext in ['.jpg', '.png', '.jpeg']:\n",
    "            path = self.img_root / f\"{name}{ext}\"\n",
    "            if path.exists():\n",
    "                return str(path)\n",
    "        raise FileNotFoundError(f\"Image file not found for {name} in {self.img_root}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['img_path']\n",
    "        label_str = row[self.label_col]\n",
    "        label = self.label2idx.get(label_str, 1)  # default 1 if unknown\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_t = self.transform(img)\n",
    "        return img_t, label, img_path\n",
    "\n",
    "class MultiTaskDeepLab(nn.Module):\n",
    "    def __init__(self, num_seg_classes:int=2, num_cls_classes:int=2):\n",
    "        super().__init__()\n",
    "        self.seg_model = deeplabv3_resnet50(weights=\"COCO_WITH_VOC_LABELS_V1\", aux_loss=True)\n",
    "        in_ch_seg = self.seg_model.classifier[-1].in_channels\n",
    "        self.seg_model.classifier[-1] = nn.Conv2d(in_ch_seg, num_seg_classes, kernel_size=1)\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(num_seg_classes, num_cls_classes)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        seg_out = self.seg_model(x)['out']\n",
    "        cls_out = self.cls_head(seg_out) \n",
    "        return seg_out, cls_out\n",
    "\n",
    "def visualize_segmentation_comparison(orig_pil, pred_mask, save_path, true_label=None, pred_label=None):\n",
    "    orig = np.array(orig_pil)\n",
    "    overlay = orig.copy()\n",
    "    if pred_mask.shape != orig.shape[:2]:\n",
    "        pred_mask = np.array(Image.fromarray(pred_mask.astype(np.uint8)).resize(\n",
    "            (orig.shape[1], orig.shape[0]), Image.NEAREST))\n",
    "    overlay[pred_mask==1] = [255,0,0]\n",
    "    blended = (0.7*orig + 0.3*overlay).astype(np.uint8)\n",
    "\n",
    "    fig, axes = plt.subplots(1,2,figsize=(10,5))\n",
    "    axes[0].imshow(orig)\n",
    "    axes[0].set_title(f\"Original\\nTrue: {true_label}\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(blended)\n",
    "    axes[1].set_title(f\"Prediction Overlay\\nPred: {pred_label}\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_csv_model(model, dataset, device, save_dir=\"misclassified_results\", max_wrong=30):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    loader = DataLoader(dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    criterion_cls = nn.CrossEntropyLoss()\n",
    "    criterion_seg = nn.CrossEntropyLoss()  # dummy mask용\n",
    "\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    total_loss = 0\n",
    "    wrong_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels, paths in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels_tensor = torch.tensor(labels, dtype=torch.long, device=device)\n",
    "\n",
    "            seg_logits, cls_logits = model(imgs)\n",
    "            loss_cls = criterion_cls(cls_logits, labels_tensor)\n",
    "            masks_dummy = torch.zeros(seg_logits.shape[0], seg_logits.shape[2], seg_logits.shape[3],\n",
    "                                      dtype=torch.long, device=device)\n",
    "            loss_seg = criterion_seg(seg_logits, masks_dummy)\n",
    "            batch_loss = (loss_cls + loss_seg).item()\n",
    "            total_loss += batch_loss * imgs.size(0)\n",
    "\n",
    "            preds_cls = torch.argmax(F.softmax(cls_logits, dim=1), dim=1)\n",
    "            total_correct += (preds_cls == labels_tensor).sum().item()\n",
    "            total_samples += imgs.size(0)\n",
    "\n",
    "            for i in range(len(labels)):\n",
    "                true_label = labels[i]\n",
    "                pred_label = preds_cls[i].item()\n",
    "\n",
    "                if preds_cls[i] != labels_tensor[i]:\n",
    "                    wrong_count += 1\n",
    "                    if wrong_count > max_wrong:\n",
    "                        continue\n",
    "                    \n",
    "                    # segmentation mask argmax\n",
    "                    pred_mask = torch.argmax(seg_logits[i], dim=0).cpu().numpy()\n",
    "                    orig = Image.open(paths[i]).convert(\"RGB\")\n",
    "                    \n",
    "                    # 파일명에 true/예측 클래스 추가\n",
    "                    save_path = Path(save_dir) / f\"wrong_{wrong_count}_true{true_label}_pred{pred_label}.jpg\"\n",
    "\n",
    "                    # overlay에 클래스 텍스트 추가\n",
    "                    visualize_segmentation_comparison(orig, pred_mask, save_path, true_label, pred_label)\n",
    "                    print(f\"[{wrong_count}] Saved: {save_path}\")\n",
    "\n",
    "\n",
    "    acc = total_correct / total_samples\n",
    "    avg_loss = total_loss / total_samples\n",
    "    print(f\"Accuracy: {acc:.4f}, Avg Loss: {avg_loss:.4f}, Wrong Samples Saved: {wrong_count}\")\n",
    "    return acc, avg_loss\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MultiTaskDeepLab(num_seg_classes=2, num_cls_classes=2).to(device)\n",
    "ckpt = torch.load(\"../runs_multitask_1000/best_multitask.pt\", map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"], strict=False)\n",
    "model.eval()\n",
    "\n",
    "# CSV 평가\n",
    "dataset = CsvImageDataset(\n",
    "    csv_path=\"../ISIC_dataset/challenge-2016-test_metadata_2025-09-01.csv\",\n",
    "    img_root=\"../ISIC_dataset/img\"\n",
    ")\n",
    "\n",
    "acc, avg_loss = evaluate_csv_model(model, dataset, device,\n",
    "                                   save_dir=\"misclassified_results_ISIC_True_false\",\n",
    "                                   max_wrong=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518473aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
