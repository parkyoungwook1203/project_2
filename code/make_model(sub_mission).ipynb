{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7daf82e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def coco_polys_to_mask(h: int, w: int, ann_list: list) -> np.ndarray:\n",
    "    rles = []\n",
    "    for ann in ann_list:\n",
    "        seg = ann.get(\"segmentation\", [])\n",
    "        if isinstance(seg, list) and len(seg) > 0 and isinstance(seg[0], str):\n",
    "            seg = [list(map(float, s.split(\",\"))) for s in seg]\n",
    "        if len(seg) == 0:\n",
    "            continue\n",
    "        rle = maskUtils.frPyObjects(seg, h, w)\n",
    "        if ann.get(\"iscrowd\", 0) == 0:\n",
    "            rle = maskUtils.merge(rle)\n",
    "        rles.append(rle)\n",
    "    if len(rles) == 0:\n",
    "        return np.zeros((h, w), dtype=np.uint8)\n",
    "    merged = maskUtils.merge(rles)\n",
    "    m = maskUtils.decode(merged)\n",
    "    if m.ndim == 3:\n",
    "        m = np.any(m, axis=2)\n",
    "    return (m > 0).astype(np.uint8)\n",
    "\n",
    "def build_image_level_label(coco: COCO, img_id: int, cat_id_to_cls: Dict[int,int]) -> int:\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=[img_id])\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    has_b, has_m = False, False\n",
    "    for a in anns:\n",
    "        c = cat_id_to_cls.get(a[\"category_id\"], 0)\n",
    "        if c == 1:\n",
    "            has_b = True\n",
    "        elif c == 2:\n",
    "            has_m = True\n",
    "    if has_m:\n",
    "        return 2\n",
    "    elif has_b:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "class COCOMultiTaskDataset(Dataset):\n",
    "    def __init__(self, root_dir: str, ann_file: str, img_size: int = 512,\n",
    "                 augment: bool = False, cache_masks_dir: str = None):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.img_ids = self.coco.getImgIds()\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        self.cache_masks_dir = Path(cache_masks_dir) if cache_masks_dir else None\n",
    "        if self.cache_masks_dir:\n",
    "            self.cache_masks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # map coco category id to our cls: benign=1, malignant=2\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        self.cat_id_to_cls = {}\n",
    "        for c in cats:\n",
    "            name = c[\"name\"].lower()\n",
    "            if \"benign\" in name:\n",
    "                self.cat_id_to_cls[c[\"id\"]] = 1\n",
    "            elif \"malig\" in name or \"cancer\" in name:\n",
    "                self.cat_id_to_cls[c[\"id\"]] = 2\n",
    "            else:\n",
    "                self.cat_id_to_cls[c[\"id\"]] = 1\n",
    "\n",
    "        self.img_trans = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def _read_image(self, info: Dict[str,Any]) -> Image.Image:\n",
    "        fname = info[\"file_name\"]\n",
    "        path = self.root_dir / fname\n",
    "        if not path.exists():\n",
    "            # images/ 폴더에 있을 수도 있음\n",
    "            alt = self.root_dir / \"images\" / fname\n",
    "            if alt.exists():\n",
    "                path = alt\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Image not found: {path} or {alt}\")\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        return img, str(path)\n",
    "\n",
    "    def _get_mask_path(self, image_info):\n",
    "        if not self.cache_masks_dir:\n",
    "            return None\n",
    "        base = Path(image_info[\"file_name\"]).stem\n",
    "        return self.cache_masks_dir / f\"{base}.png\"\n",
    "\n",
    "    def _ensure_mask(self, img_info, anns, h, w):\n",
    "        mask_path = self._get_mask_path(img_info)\n",
    "        if mask_path and mask_path.exists():\n",
    "            m = np.array(Image.open(mask_path).convert(\"L\"))\n",
    "            return (m>0).astype(np.uint8)\n",
    "        lesion_anns = [a for a in anns if self.cat_id_to_cls.get(a[\"category_id\"],0) in (1,2)]\n",
    "        m = coco_polys_to_mask(h, w, lesion_anns)\n",
    "        if mask_path:\n",
    "            Image.fromarray((m*255).astype(np.uint8)).save(mask_path)\n",
    "        return m\n",
    "\n",
    "    def _resize_keep_ratio(self, img: Image.Image, mask: np.ndarray, size: int):\n",
    "        w, h = img.size\n",
    "        scale = size / max(h, w)\n",
    "        nh, nw = int(round(h*scale)), int(round(w*scale))\n",
    "        img_r = img.resize((nw, nh), Image.BILINEAR)\n",
    "        mask_r = cv2.resize(mask.astype(np.uint8), (nw, nh), interpolation=cv2.INTER_NEAREST)\n",
    "        pad_h = size - nh\n",
    "        pad_w = size - nw\n",
    "        img_p = Image.new(\"RGB\", (size, size))\n",
    "        img_p.paste(img_r, (pad_w//2, pad_h//2))\n",
    "        mask_p = np.zeros((size, size), dtype=np.uint8)\n",
    "        mask_p[pad_h//2:pad_h//2+nh, pad_w//2:pad_w//2+nw] = mask_r\n",
    "        return img_p, mask_p\n",
    "\n",
    "    def to_tensor(self, img: Image.Image):\n",
    "        return self.img_trans(img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "        info = self.coco.loadImgs([img_id])[0]\n",
    "        img, _ = self._read_image(info)\n",
    "        h, w = info[\"height\"], info[\"width\"]\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=[img_id])\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        mask_full = self._ensure_mask(info, anns, h, w)\n",
    "        img_label = build_image_level_label(self.coco, img_id, self.cat_id_to_cls)\n",
    "        img_sq, mask_sq = self._resize_keep_ratio(img, mask_full, self.img_size)\n",
    "        img_t = self.to_tensor(img_sq)\n",
    "        mask_t = torch.from_numpy(mask_sq).long()\n",
    "        cls_t = torch.tensor(img_label-1, dtype=torch.long) \n",
    "\n",
    "        return img_t, mask_t, cls_t, info.get(\"file_name\", str(img_id))\n",
    "\n",
    "\n",
    "class MultiTaskDeepLab(nn.Module):\n",
    "    def __init__(self, num_seg_classes:int=2, num_cls_classes:int=2, freeze_until: str = None):\n",
    "        super().__init__()\n",
    "        self.seg_model = deeplabv3_resnet50(weights=\"COCO_WITH_VOC_LABELS_V1\", aux_loss=True)\n",
    "        in_ch = self.seg_model.classifier[-1].in_channels\n",
    "        self.seg_model.classifier[-1] = nn.Conv2d(in_ch, num_seg_classes, kernel_size=1)\n",
    "        self.backbone = self.seg_model.backbone\n",
    "\n",
    "        if freeze_until:\n",
    "            for name,p in self.backbone.named_parameters():\n",
    "                p.requires_grad = True\n",
    "                if freeze_until == \"layer3\":\n",
    "                    if not (name.startswith(\"layer3\") or name.startswith(\"layer4\")):\n",
    "                        p.requires_grad = False\n",
    "\n",
    "        self.cls_gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2048,512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512,num_cls_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        seg_out = self.seg_model(x)[\"out\"]\n",
    "        feats = self.backbone(x)[\"out\"]\n",
    "        pooled = self.cls_gap(feats)\n",
    "        cls_logits = self.cls_head(pooled)\n",
    "        return seg_out, cls_logits\n",
    "\n",
    "def pixel_iou_and_dice(pred: torch.Tensor, target: torch.Tensor, num_classes: int = 2) -> Dict[str, float]:\n",
    "    \"\"\"pred: logits [B,C,H,W] or pred labels [B,H,W]; target: [B,H,W]\"\"\"\n",
    "    if pred.ndim == 4:\n",
    "        pred_lbl = pred.argmax(1)\n",
    "    else:\n",
    "        pred_lbl = pred\n",
    "    target = target\n",
    "    ious = []\n",
    "    dices = []\n",
    "    for c in range(1, num_classes):  \n",
    "        pred_c = (pred_lbl == c)\n",
    "        tgt_c = (target == c)\n",
    "        inter = (pred_c & tgt_c).sum().item()\n",
    "        union = (pred_c | tgt_c).sum().item()\n",
    "        iou = inter / union if union > 0 else float('nan')\n",
    "        dice = (2*inter) / (pred_c.sum().item() + tgt_c.sum().item()) if (pred_c.sum().item()+tgt_c.sum().item())>0 else float('nan')\n",
    "        ious.append(iou)\n",
    "        dices.append(dice)\n",
    "\n",
    "    ious_valid = [v for v in ious if not math.isnan(v)]\n",
    "    dices_valid = [v for v in dices if not math.isnan(v)]\n",
    "    return {\n",
    "        \"miou_fg\": float(np.mean(ious_valid)) if ious_valid else 0.0,\n",
    "        \"mdice_fg\": float(np.mean(dices_valid)) if dices_valid else 0.0\n",
    "    }\n",
    "\n",
    "def train_one_epoch(model, loader, optim, scaler, device, seg_loss_w=1.0, cls_loss_w=1.0):\n",
    "    model.train()\n",
    "    running = {\"loss\":0.0, \"seg\":0.0, \"cls\":0.0}\n",
    "    n = 0\n",
    "    pbar = tqdm(loader, desc=\"train\", leave=False)\n",
    "    seg_criterion = nn.CrossEntropyLoss()\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    for imgs, masks, cls_lbls, _ in pbar:\n",
    "        imgs = imgs.to(device)\n",
    "        masks = masks.to(device)          # [B,H,W] values 0/1\n",
    "        # cls_lbls: -1(ignore)/0/1\n",
    "        cls_targets = cls_lbls.clone().to(device)\n",
    "        valid_mask = (cls_targets >= 0)\n",
    "        cls_targets_valid = torch.clamp(cls_targets, min=0)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
    "            seg_logits, cls_logits = model(imgs)\n",
    "            loss_seg = seg_criterion(seg_logits, masks)\n",
    "            if valid_mask.any():\n",
    "                loss_cls = cls_criterion(cls_logits[valid_mask], cls_targets_valid[valid_mask])\n",
    "            else:\n",
    "                loss_cls = torch.tensor(0.0, device=device)\n",
    "            loss = seg_loss_w * loss_seg + cls_loss_w * loss_cls\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        running[\"loss\"] += loss.item() * bs\n",
    "        running[\"seg\"] += loss_seg.item() * bs\n",
    "        running[\"cls\"] += loss_cls.item() * bs\n",
    "        n += bs\n",
    "    for k in running:\n",
    "        running[k] = running[k] / n\n",
    "    return running\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    seg_criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    cls_criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    tot = {\"loss\":0.0, \"seg\":0.0, \"cls\":0.0}\n",
    "    n = 0\n",
    "    seg_metrics = []\n",
    "    all_labels = []\n",
    "    all_preds_proba = []\n",
    "    correct = 0\n",
    "    cls_count = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, cls_lbls, _ in tqdm(loader, desc=\"eval\", leave=False):\n",
    "            imgs = imgs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            cls_targets = cls_lbls.clone().to(device)\n",
    "            valid_mask = (cls_targets >= 0)\n",
    "            cls_targets_valid = torch.clamp(cls_targets, min=0)\n",
    "\n",
    "            seg_logits, cls_logits = model(imgs)\n",
    "            loss_seg = seg_criterion(seg_logits, masks)\n",
    "            loss_cls = cls_criterion(cls_logits[valid_mask], cls_targets_valid[valid_mask]) if valid_mask.any() else torch.tensor(0.0, device=device)\n",
    "            loss = loss_seg + loss_cls\n",
    "\n",
    "            bs = imgs.size(0)\n",
    "            tot[\"loss\"] += loss.item()\n",
    "            tot[\"seg\"] += loss_seg.item()\n",
    "            tot[\"cls\"] += loss_cls.item()\n",
    "            n += bs\n",
    "\n",
    "            seg_metrics.append(pixel_iou_and_dice(seg_logits.cpu(), masks.cpu(), num_classes=2))\n",
    "\n",
    "            if valid_mask.any():\n",
    "                probs = F.softmax(cls_logits, dim=1)[:,1].cpu().numpy().tolist()  \n",
    "                preds = cls_logits.argmax(1).cpu().numpy()\n",
    "                labs = cls_targets_valid.cpu().numpy()\n",
    "                all_preds_proba.extend(probs)\n",
    "                all_labels.extend(labs.tolist())\n",
    "                correct += int((preds[valid_mask.cpu().numpy()]==labs[valid_mask.cpu().numpy()]).sum())\n",
    "                cls_count += int(valid_mask.sum().item())\n",
    "\n",
    "    avg = {k: v / n for k,v in tot.items()}\n",
    "    if seg_metrics:\n",
    "        avg[\"miou_fg\"] = float(np.mean([m[\"miou_fg\"] for m in seg_metrics]))\n",
    "        avg[\"mdice_fg\"] = float(np.mean([m[\"mdice_fg\"] for m in seg_metrics]))\n",
    "    avg[\"cls_acc\"] = (correct / cls_count) if cls_count>0 else 0.0\n",
    "    try:\n",
    "        avg[\"cls_auc\"] = roc_auc_score(all_labels, all_preds_proba) if len(set(all_labels))>1 else 0.0\n",
    "    except Exception:\n",
    "        avg[\"cls_auc\"] = 0.0\n",
    "    return avg\n",
    "\n",
    "def visualize_and_save(model, loader, device, out_dir: str, n_samples: int = 16):\n",
    "    model.eval()\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    saved = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks, cls_lbls, paths in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            seg_logits, cls_logits = model(imgs)\n",
    "            seg_pred = seg_logits.argmax(1).cpu().numpy()\n",
    "            probs = F.softmax(cls_logits, dim=1).cpu().numpy()\n",
    "            for i in range(imgs.size(0)):\n",
    "                if saved >= n_samples:\n",
    "                    return\n",
    "                p = paths[i]\n",
    "                try:\n",
    "                    orig = Image.open(p).convert(\"RGB\")\n",
    "                except FileNotFoundError:\n",
    "                    print(f\"[WARNING] Could not find image: {p}\")\n",
    "                    continue\n",
    "                # resize seg_pred to orig size using metadata - assume square input\n",
    "                mask = seg_pred[i].astype(np.uint8)\n",
    "                mask_up = cv2.resize(mask, orig.size, interpolation=cv2.INTER_NEAREST)\n",
    "                overlay = np.array(orig).copy()\n",
    "                overlay[mask_up==1] = (overlay[mask_up==1]*0.5 + np.array([255,0,0])*0.5).astype(np.uint8)  # red lesion\n",
    "                savep = Path(out_dir)/f\"vis_{saved}.png\"\n",
    "                Image.fromarray(overlay).save(savep)\n",
    "                saved += 1\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--data_root\", type=str, default=\"dataset_1000\")\n",
    "    p.add_argument(\"--epochs\", type=int, default=30)\n",
    "    p.add_argument(\"--batch_size\", type=int, default=8)\n",
    "    p.add_argument(\"--img_size\", type=int, default=512)\n",
    "    p.add_argument(\"--lr\", type=float, default=3e-4)\n",
    "    p.add_argument(\"--freeze_until\", type=str, default=None)\n",
    "    p.add_argument(\"--seg_loss_w\", type=float, default=1.0)\n",
    "    p.add_argument(\"--cls_loss_w\", type=float, default=1.0)\n",
    "    p.add_argument(\"--cache_masks_dir\", type=str, default=\"masks_cache_1000_ver2\")\n",
    "    p.add_argument(\"--num_workers\", type=int, default=4)\n",
    "    p.add_argument(\"--output_dir\", type=str, default=\"runs_multitask_1000_ver2\")\n",
    "    p.add_argument(\"--use_amp\", action=\"store_true\")\n",
    "    return p.parse_args()\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    seed_everything(42)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "\n",
    "    def split_paths(split):\n",
    "        ann = Path(args.data_root)/split/\"_annotations.coco.json\"\n",
    "        if not ann.exists():\n",
    "            # fallback: any json\n",
    "            alt = list((Path(args.data_root)/split).glob(\"*.json\"))\n",
    "            if not alt:\n",
    "                raise FileNotFoundError(f\"No COCO json under {args.data_root}/{split}\")\n",
    "            ann = alt[0]\n",
    "        return str(Path(args.data_root)/split), str(ann)\n",
    "\n",
    "    train_dir, train_ann = split_paths(\"train\")\n",
    "    val_dir, val_ann = split_paths(\"valid\") if (Path(args.data_root)/\"valid\").exists() else split_paths(\"valid\")\n",
    "    \n",
    "    ds_train = COCOMultiTaskDataset(train_dir, train_ann, img_size=args.img_size, augment=True, cache_masks_dir=args.cache_masks_dir)\n",
    "    ds_val = COCOMultiTaskDataset(val_dir, val_ann, img_size=args.img_size, augment=False, cache_masks_dir=args.cache_masks_dir)\n",
    "\n",
    "    def collate(batch):\n",
    "        imgs, masks, clss, paths = zip(*batch)\n",
    "        imgs = torch.stack(imgs)\n",
    "        masks = torch.stack(masks)\n",
    "        clss = torch.stack(clss)\n",
    "        return imgs, masks, clss, list(paths)\n",
    "\n",
    "    dl_train = DataLoader(ds_train, batch_size=args.batch_size, shuffle=True,\n",
    "                          num_workers=args.num_workers, collate_fn=collate,\n",
    "                          pin_memory=True, drop_last=True)  # drop_last=True 추가\n",
    "    dl_val = DataLoader(ds_val, batch_size=args.batch_size, shuffle=False,\n",
    "                        num_workers=args.num_workers, collate_fn=collate,\n",
    "                        pin_memory=True, drop_last=False)\n",
    "\n",
    "    model = MultiTaskDeepLab(num_seg_classes=2, num_cls_classes=2, freeze_until=args.freeze_until).to(device)\n",
    "\n",
    "    optimizer = optim.AdamW([p for p in model.parameters() if p.requires_grad], lr=args.lr, weight_decay=1e-4)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.use_amp and torch.cuda.is_available())\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs)\n",
    "\n",
    "    writer = SummaryWriter(log_dir=os.path.join(args.output_dir, \"tb\"))\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_path = os.path.join(args.output_dir, \"best_multitask.pt\")\n",
    "\n",
    "    for epoch in range(1, args.epochs+1):\n",
    "        t0 = time.time()\n",
    "        tr = train_one_epoch(model, dl_train, optimizer, scaler if args.use_amp else None, device, seg_loss_w=args.seg_loss_w, cls_loss_w=args.cls_loss_w)\n",
    "        va = evaluate(model, dl_val, device)\n",
    "        score = 0.5 * va.get(\"miou_fg\", 0.0) + 0.5 * va.get(\"cls_acc\", 0.0)\n",
    "        dt = time.time()-t0\n",
    "\n",
    "        print(f\"Epoch {epoch}/{args.epochs}  time={dt:.1f}s | train_loss={tr['loss']:.4f} seg={tr['seg']:.4f} cls={tr['cls']:.4f} | val_mIoU={va.get('miou_fg',0):.3f} val_cls_acc={va.get('cls_acc',0):.3f} val_auc={va.get('cls_auc',0):.3f} score={score:.4f}\")\n",
    "        writer.add_scalar(\"train/loss\", tr[\"loss\"], epoch)\n",
    "        writer.add_scalar(\"train/seg_loss\", tr[\"seg\"], epoch)\n",
    "        writer.add_scalar(\"train/cls_loss\", tr[\"cls\"], epoch)\n",
    "        writer.add_scalar(\"val/miou\", va.get(\"miou_fg\",0), epoch)\n",
    "        writer.add_scalar(\"val/mdice\", va.get(\"mdice_fg\",0), epoch)\n",
    "        writer.add_scalar(\"val/cls_acc\", va.get(\"cls_acc\",0), epoch)\n",
    "        writer.add_scalar(\"val/cls_auc\", va.get(\"cls_auc\",0), epoch)\n",
    "        writer.add_scalar(\"val/score\", score, epoch)\n",
    "        writer.add_scalar(\"lr\", optimizer.param_groups[0][\"lr\"], epoch)\n",
    "\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            torch.save({\"model\": model.state_dict(), \"epoch\": epoch, \"score\": best_score}, best_path)\n",
    "            print(f\"✔ Saved best to {best_path} (score {best_score:.4f})\")\n",
    "\n",
    "        scheduler.step()\n",
    "        if epoch % 5 == 0:\n",
    "            vis_dir = os.path.join(args.output_dir, f\"vis_epoch{epoch}\")\n",
    "            visualize_and_save(model, dl_val, device, vis_dir, n_samples=16)\n",
    "\n",
    "    writer.close()\n",
    "    print(\"Training finished. Best score:\", best_score, \"->\", best_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
