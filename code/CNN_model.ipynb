{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "DATA_DIR = \"./data\"\n",
    "TARGET_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "SHUFFLE = True\n",
    "\n",
    "class SkinDiseaseDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "        self.class_to_idx = {class_name: idx for idx, class_name in enumerate(self.class_names)}\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                    path = os.path.join(class_dir, filename)\n",
    "                    self.images.append(path)\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((TARGET_SIZE, TARGET_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = SkinDiseaseDataset(os.path.join(DATA_DIR, \"train\"), transform=transform)\n",
    "test_dataset = SkinDiseaseDataset(os.path.join(DATA_DIR, \"test\"), transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"총 학습 이미지 수: {len(train_dataset)}\")\n",
    "print(f\"총 테스트 이미지 수: {len(test_dataset)}\")\n",
    "print(f\"클래스 매핑: {train_dataset.class_to_idx}\")\n",
    "\n",
    "for imgs, labels in train_loader:\n",
    "    print(\"배치 이미지 크기:\", imgs.shape)\n",
    "    print(\"배치 라벨:\", labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ff4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding='same')\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding='same')\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=2, padding='same')\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=2, padding='same')\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=2, padding='same')\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=2, padding='same')\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=2, padding='same')\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=2, padding='same')\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc_out = nn.Linear(64, num_classes)\n",
    "        \n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d1ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device, dtype=torch.long)\n",
    "            \n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item() * data.size(0)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    acc = 100. * correct / len(loader.dataset)\n",
    "    return avg_loss, acc\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs):\n",
    "    train_loss_list = []\n",
    "    train_acc_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for data, target in train_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * len(data)\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            total_samples += len(data)\n",
    "\n",
    "        epoch_loss = total_loss / total_samples\n",
    "        train_acc = 100. * correct / total_samples\n",
    "        \n",
    "        train_loss_list.append(epoch_loss)\n",
    "        train_acc_list.append(train_acc)\n",
    "        \n",
    "        val_loss, val_acc = test(model, val_loader, criterion)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "\n",
    "        print(f'Epoch: {epoch+1}/{epochs} | '\n",
    "              f'Train Loss: {epoch_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
    "              f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%')\n",
    "    \n",
    "    return train_loss_list, train_acc_list, val_loss_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c28f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adamax(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "\n",
    "torchinfo.summary(model, input_size=(1, 3, 128, 128), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5594176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "incorrect_preds = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        incorrect_indices = (preds != labels).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        for idx in incorrect_indices:\n",
    "            image = images[idx].cpu().permute(1, 2, 0)\n",
    "            pred = preds[idx].cpu().item()\n",
    "            label = labels[idx].cpu().item()\n",
    "            incorrect_preds.append((image, pred, label))\n",
    "\n",
    "num_to_plot = min(len(incorrect_preds), 25)\n",
    "random_incorrect_preds = random.sample(incorrect_preds, num_to_plot)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "fig.suptitle('Incorrect Predictions (Predicted vs. True Label)', fontsize=20)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(random_incorrect_preds):\n",
    "        image, pred, label = random_incorrect_preds[i]\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(f'pred: {pred}, True: {label}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "class_mapping = {'Acne': 0, 'Eczema': 1, 'Psoriasis': 2}\n",
    "incorrect_by_label = {label: 0 for label in class_mapping.values()}\n",
    "total_by_label = {label: 0 for label in class_mapping.values()}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        for label in labels:\n",
    "            total_by_label[label.item()] += 1\n",
    "        incorrect_indices = (preds != labels).nonzero(as_tuple=True)[0]\n",
    "\n",
    "        for idx in incorrect_indices:\n",
    "\n",
    "            true_label = labels[idx].item()\n",
    "            incorrect_by_label[true_label] += 1\n",
    "\n",
    "print(\"--- 라벨별 오답 개수 (총 265개 테스트 이미지) ---\")\n",
    "print(f\"클래스 매핑: {class_mapping}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for name, label_id in class_mapping.items():\n",
    "    total = total_by_label[label_id]\n",
    "    incorrect = incorrect_by_label[label_id]\n",
    "    accuracy = (total - incorrect) / total * 100 if total > 0 else 0\n",
    "    \n",
    "    print(f\"'{name}' (라벨 {label_id})\")\n",
    "    print(f\"  총 이미지 수: {total}\")\n",
    "    print(f\"  오답 예측 수: {incorrect}\")\n",
    "    print(f\"  정확도: {accuracy:.2f}%\")\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fi_pro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
